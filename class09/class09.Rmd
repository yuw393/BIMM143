---
title: 'Class 9: Unsupervised Learning Mini-Project'
author: "Yutong Wu"
date: "10/29/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data input


```{r}
input.file <- "https://bioboot.github.io/bimm143_F19/class-material/WisconsinCancer.csv"

#wisc.df <- read.csv("WisconsinCancer.csv")
wisc.df <- read.csv(input.file)
head(wisc.df)
```

Note that the `id` and `diagnosis` columns will not be used for most of the following steps 

We have `r nrow(wisc.df)` samples in this dataset

```{r}
nrow(wisc.df)
```

How many benign (not cancerous) and and malignant (cancerous) samples do we have in the dataset?

```{r}
table(wisc.df$diagnosis)
```

```{r}
# Convert the features of the data: wisc.data
wisc.data <- as.matrix(wisc.df[,3:32])
wisc.data

# Set the row names of wisc.data
row.names(wisc.data) <- wisc.df$id

head(wisc.data)
```

Store the diagnosis for reference in the future as a separate vector

```{r}
diagnosis <- wisc.df$diagnosis
```

## Questions:

- Q1. How many observations are in this dataset?
```{r}
nrow(wisc.df)
```

- Q2. How many of the observations have a malignant diagnosis?
```{r}
table(wisc.df$diagnosis)
```

- Q3. How many variables/features in the data are suffixed with _mean?
```{r}
colnames(wisc.df)
```

```{r}
grep("_mean", colnames(wisc.df), value = TRUE)
```

I can use `length()` to count how many matches we have.

```{r}
length( grep("_mean", colnames(wisc.df)) )
```

# Performing PCA
The next step in your analysis is to perform principal component analysis (PCA) on wisc.data.

It is important to check if the data need to be scaled before performing PCA. Recall two common reasons for scaling data include:

The input variables use different units of measurement.
The input variables have significantly different variances.
Check the mean and standard deviation of the features (i.e. columns) of the wisc.data to determine if the data should be scaled. Use the colMeans() and apply() functions like you’ve done before.


```{r}
round( colMeans(wisc.data), 3)
```

```{r}
wisc.data
round( apply(wisc.data, 2, sd), 3)
```

These values look very different so I will use `scale=TRUE` when I run PCA.

```{r}
# Perform PCA on wisc.data 
wisc.pr <- prcomp( wisc.data, scale= TRUE )
summary(wisc.pr)
attributes(wisc.pr)
```

```{r}
plot(wisc.pr)
```

Lets make a plot of PC1 vs PC2 

```{r}
plot(wisc.pr$x[,1],  wisc.pr$x[,2])
```

Color by cancer/non-cancer...
```{r}
plot(wisc.pr$x[,1],  wisc.pr$x[,2], col=diagnosis,
     xlab="PC1", ylab="PC2")
```


## Questions
- Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

```{r}
x <- summary(wisc.pr)
x$importance[,"PC1"]
#x$importance[,1]
```

- Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

```{r}
x$importance
x$importance[3,] 
#3 PCs
```

- Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

```{r}
which(x$importance[3,] > 0.9 )[1]
x$importance
```

Overall, the plots indicate that principal component 1 is capturing a separation of malignant from benign samples. This is an important and interesting result worthy of further exploration - as we will do in the next sections!


### Side-note:

There are quite a few CRAN packages that are helpful for PCA. This includes the factoextra package. Feel free to explore this package. For example:

```{r}
## ggplot based graph
#install.packages("factoextra")
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

## Communicating PCA results
In this section we will check your understanding of the PCA results, in particular the loadings and variance explained. The loadings, represented as vectors, explain the mapping from the original features to the principal components. The principal components are naturally ordered from the most variance explained to the least variance explained.

### Questions
- Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?


```{r}
wisc.pr$rotation
wisc.pr$rotation["concave.points_mean",1]
```

- Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
x$importance
x <- summary(wisc.pr)
which(x$importance["Cumulative Proportion",] > 0.8)[1]
```

## Hierarchical clustering
Here we hierarchical clustering of case data and then on the PCA results...

First original data - this tree is ugly!
```{r}
wisc.hclust <- hclust( dist( scale(wisc.data)) )
plot(wisc.hclust)
```

Let’s see if PCA improves or degrades the performance of hierarchical clustering.
```{r}
wisc.pr.hclust <- hclust( dist(wisc.pr$x[,1:7]),
                          method="ward.D2")
```

Using the minimum number of principal components required to describe at least 90% of the variability in the data, create a hierarchical clustering model with the linkage method="ward.D2". We use Ward’s criterion here because it is based on multidimensional variance like principal components analysis. Assign the results to wisc.pr.hclust.

```{r}
plot(wisc.pr.hclust)
```

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

This table below tells me that cluster 1 is mostly "M" i.e. cancer and cluster 2 is mostly "B" i.e. non-cancer. In this regard there are 28 False Positives and 24 False Negatives.

```{r}
table(grps, diagnosis)
```

## Jump to section 7: Prediction

We will use the predict() function that will take our PCA model from before and new cancer cell data and project that data onto our PCA space.

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

Plot these new samples on our PC1 vs PC2 plot...

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis)
points(npc[,1], npc[,2], col="blue", pch=15, cex=3)
text(npc[,1], npc[,2], labels = c(1,2), col="white")
```

